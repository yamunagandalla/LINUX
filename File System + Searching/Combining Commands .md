# Combining Commands: grep | sort | uniq

This is a powerful command chain used to:

âœ… Search
âœ… Organize
âœ… Remove duplicates

All in one line.

---

## ğŸ§± Basic Structure

```bash
grep "pattern" filename | sort | uniq
```

| Command | Job                           |
| ------- | ----------------------------- |
| grep    | Finds matching lines          |
| sort    | Arranges lines alphabetically |
| uniq    | Removes duplicate lines       |

---

## ğŸ§  How Data Flows

File â†’ grep â†’ matching lines â†’ sort â†’ ordered lines â†’ uniq â†’ unique lines

Each command processes the output of the previous one.

---

## ğŸ” Step 1: grep â€” Filter the Data

`grep` searches for a word or pattern.

```bash
grep "error" log.txt
```

ğŸ“¤ Output â†’ Only lines that contain "error"

---

## ğŸ”¤ Step 2: sort â€” Arrange the Data

`sort` puts lines in alphabetical (or numerical) order.

```bash
grep "error" log.txt | sort
```

Now all matching lines are grouped together, which helps `uniq` work properly.

---

## ğŸš« Step 3: uniq â€” Remove Duplicates

`uniq` removes adjacent duplicate lines.

```bash
grep "error" log.txt | sort | uniq
```

ğŸ“¤ Output â†’ Only one copy of each matching line

---

## â— Important Rule

ğŸ”´ `uniq` only removes duplicates that are next to each other

Thatâ€™s why we use:

```bash
sort | uniq
```

instead of just:

```bash
uniq
```

---

## âœ… Example 1: Find Unique Error Messages

```bash
grep "error" log.txt | sort | uniq
```

âœ” Searches all "error" lines
âœ” Sorts them
âœ” Removes repeated ones

ğŸ“¤ Final Output â†’ List of unique error messages

---

## ğŸ”¢ Example 2: Count Unique Occurrences

Add `-c` to `uniq` to count duplicates:

```bash
grep "error" log.txt | sort | uniq -c
```

ğŸ“¤ Output:

```
3 Disk error
5 Network error
1 Login error
```

| Number | Meaning                          |
| ------ | -------------------------------- |
| 3      | "Disk error" appeared 3 times    |
| 5      | "Network error" appeared 5 times |

---

## ğŸ† Example 3: Most Frequent Items

```bash
grep "error" log.txt | sort | uniq -c | sort -nr
```

| Part     | Meaning                                 |
| -------- | --------------------------------------- |
| uniq -c  | Count occurrences                       |
| sort -nr | Sort numbers in reverse (largest first) |

ğŸ“¤ Output â†’ Most common errors at the top

---

## ğŸ§ª Example 4: Unique Names from a File

```bash
cat students.txt | sort | uniq
```

Removes duplicate student names.

Better version (no need for `cat`):

```bash
sort students.txt | uniq
```

---

## âš¡ Real-World Uses

| Situation                  | Command                  |
| -------------------------- | ------------------------ |
| Unique IP addresses in log | `grep "192." access.log` |
| Unique usernames           | `cut -d' ' -f1 file.txt` |
| Count repeated words       | `tr ' ' '\n' < file.txt` |

---

## ğŸ§  Visual Analogy

Think of it like a factory line ğŸ­

1ï¸âƒ£ grep â†’ Picks only useful items
2ï¸âƒ£ sort â†’ Arranges them neatly
3ï¸âƒ£ uniq â†’ Throws away duplicates

---

## ğŸ†š Without vs With Sorting

âŒ Wrong Order

```bash
grep "error" log.txt | uniq
```

Duplicates may remain because they arenâ€™t together.

âœ… Correct Order

```bash
grep "error" log.txt | sort | uniq
```

---

## ğŸ¯ Summary

âœ” grep filters
âœ” sort organizes
âœ” uniq removes duplicates
âœ” Use `uniq -c` to count
âœ” Use `sort -nr` after counting to find most frequent items
